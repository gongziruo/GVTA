#gp import
import inspect
import numpy as np
import math
import scipy
from scipy.optimize import minimize
from numpy import nan
import copy
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.pyplot import MultipleLocator
import sys

import os

class GP(object):
    def __init__(hyp,sn,ell_1,sf):
        hyp.mean = []  # meanzero
        hyp.lik = math.log(sn)  # likelihood
        hyp.cov = np.r_[math.log(ell_1),math.log(sf)]  # cov

    def sq_list(hyp,a,b=[]):
        D = np.shape(a)
        n=1
        bsx = 1
        if b == [] :# subtract mean
            mu = np.mean(a)

            if bsx:
                a = a-mu

            else:
                a = a - np.kron(np.ones((1,np.shape(a)[1])), mu)#repmat(mu, 1, size(a, 2))
            b = a

            m = n
        else:
            d= np.shape(b)[0]
            m=1
            if d != D:
                print('Error: column lengths must agree.')
            mu = (m / (n + m)) * np.mean(b, axis=0) + (n / (n + m)) * np.mean(a,axis=0)
            if bsx:
                a = a-mu
                b = b-mu
            else:
                a = a - np.kron(np.ones((1,n)), mu)#repmat(mu, 1, n)
                b = b - np.kron(np.ones((1,m)), mu)#repmat(mu, 1, m)
        if bsx :#compute squared distances
            a2 = np.mat(a * a).T
            b2 = np.mat(b * b)

            ab2 = 2 * np.dot(np.mat(a).T, np.mat(b))

            C = a2+b2-ab2
        else:
            C = np.kron(np.ones((1,m)), np.sum(a* a, axis=0).T)+np.kron(np.ones((1,n)), np.sum(b*b,axis=0))
        C=np.where(C > 1e-4, C, 0)
        return C
    def meanZero(hyp, x=[]):
        if len(x)==0:
            A = '0'
            return A
        else:
            A = np.zeros([np.shape(x)[0], 1])
            return A
    def covSEiso(hyp,parm,x=[],z=[],i=[]):
        if len(x)==0: #report number of parameters
            K=2
            return K
        if z==[]:
            xeqz = 1
        if len(z) > 0:
            if z is 'diag':
                dg=1
        else:
            dg=0
        #determine mode
        ell = np.exp(parm["cov"][0])#characteristic length scale
        sf2 = math.exp(2 * parm["cov"][1])#signal variance
        if dg:
            K = np.zeros([np.shape(x)[0],1])#zeros(size(x, 1), 1)
        else:
            if xeqz:
                K = hyp.sq_list(x.T /ell)
            else:
                K = hyp.sq_list(x.T/ell,z.T *(1/ell))

        if i ==[] :  #covariances:
            K = sf2 * np.exp((-1)*K / 2)

        else : # derivatives
            if i == 0:
                K = sf2 * np.exp((-1)*K / 2)* K

            elif i == 1:
                K = 2 * sf2 * np.exp((-1)*K / 2)

            else:
                print('Unknown hyperparameter')
        K=np.where(K > 1e-4, K, 0)

        # sns.heatmap(K, annot=True)
        # plt.show()
        return K
    #高斯似然度
    def likGauss(hyp,y, mu=[], s2=[], inf=[], i=[]):
        if mu ==[]:
            varargout = 1
            return varargout
        sn2 = np.exp(2 * hyp.lik)

        if inf ==[]:
            if sum(p.numel() for p in list(y))==0:#numel(y) == 0:
                y = np.zeros(mu.shape)
            s2zero = 1
            if s2 !=[]:
                if np.linalg.norm(s2) > 0:
                    s2zero = 0
            if s2zero:
                lp = -(y - mu)^ 2 / sn2 / 2 - math.log(2 * pi * sn2) / 2
                s2 = 0
        return varargout


    def infExact_delayed(hyp,parm, T,N=0,p=0,sign=0,x=[],y=[],DX=[],X0=[]):
        n = np.shape(y)[0]
        K = hyp.covSEiso(parm,x) #evaluate covariance matrix
        #print("K",K)
        m = hyp.meanZero(x) #evaluate mean vector, consant mean or zero mean
        m_all = np.dot(DX,np.ones((np.shape(DX)[1], 1))) * m[0]
        tmp1 = np.dot(X0 , X0.T)*K

        sn2 = np.exp(2 * parm["lik"])

        if sn2 < 1e-6:
            P = tmp1 + sn2 * np.eye(np.shape(K)[1])
            sl = 1
        else:

            P = tmp1 / sn2 + np.eye(np.shape(K)[1])
            sl = sn2
        LL=scipy.linalg.cholesky(P)

        L = np.kron(LL, np.eye(N))
        LL_inv=np.linalg.inv(LL) #LL_inv=inv(LL)

        K_total_inv = np.kron(LL_inv * LL_inv.T,np.eye(N))
        alpha = np.dot(K_total_inv , (y - m_all) )/ sl

        nlZ = np.dot((y - m_all).T,alpha)/2 + np.sum(np.log(np.diag(L))) + n*np.log(2*(math.pi)*sl)/2

        #wc
        tmp0 = np.kron(LL_inv, np.eye(N))
        Q = np.dot(tmp0 , tmp0.T)/sl - np.dot(alpha,alpha.T)

        dnlZ=copy.deepcopy(parm)
        for i in range((np.shape(parm["cov"])[0])):
            dnlZ["cov"][i] = sum(sum(Q* (np.kron(np.dot(X0 , X0.T)*(hyp.covSEiso(parm, x, [], i)),np.eye(N)))))/2
        dnlZ["lik"] = sn2 * np.trace(Q)
        # for i in range(np.shape(parm["mean"])):
        #     tmp = hyp.meanZero(x, i)
        #     parm["mean"][i] = -(DX * np.ones((np.shape(DX)[1], 1)) * tmp(1)).T*alpha
        if sign:
            K_extend = np.kron(K, np.eye(int((np.shape(DX)[1]) / len(x)))) # kronecker product

            m_extend = np.ones((np.shape(DX)[1], 1)) * m[0,0]

            posterior_mean = m_extend + np.dot((np.dot(DX , K_extend)).T,alpha)

            posterior_covariance = K_extend - np.dot(np.dot((np.dot(DX , K_extend)).T,np.dot(np.linalg.inv(L),np.linalg.inv(L.T))) / sl ,np.dot(DX , K_extend))
            nlhood = np.dot((y - m_all).T,(y-m_all))/np.exp(2*parm["lik"])/2+parm["lik"] + n*np.log(2*math.pi)/2

            return nlZ, dnlZ, nlhood, posterior_mean, posterior_covariance
        else:
            return nlZ, dnlZ

    def gp_my(hyp,parm, T=0, N=0, p=0, sign=0, x=[], y=[], DX2=[], X0=[]):
        D = np.shape(x)[0]
        try:
            if T == 0:
                nlZ = hyp.infExact_delayed(parm, x, y, T, N, p, sign, x, y, DX2, X0)
                dnlZ = {}
            else:
                nlZ, dnlZ = hyp.infExact_delayed( parm,T, N, p, sign, x, y, DX2, X0)
        except:
            print('Inference method failed [%s] .. attempting to continue')
            dnlZ = {'cov': 0 * hyp.cov, 'mean': 0 * hyp.mean, 'lik': 0 * hyp.lik}
            varargout = [nan, dnlZ]
            return varargout
        varargout = nlZ, dnlZ
        return varargout

    def rewrap(hyp,s):
        v={"mean": hyp.mean, "lik": hyp.lik, "cov": hyp.cov}
        v["cov"][0]=s.tolist()[0][0]
        v["cov"][1]=s.tolist()[0][1]
        v["lik"]=s.tolist()[0][2]
        #print(v)
        return v

    def minimize(hyp,parm, length, T, N, p, sign, x, y, DX, x0):
        INT = 0.1
        EXT = 3.0
        MAX = 20
        RATIO = 10
        SIG = 0.1
        RHO = SIG / 2
        red=1
        i = 0 # zero the run length counter
        ls_failed = 0

        f0, df0 = hyp.gp_my(parm,T, N, p, sign, x, y, DX, x0)

        parm=[parm["cov"][0],parm["cov"][1],parm["lik"]]#1,3
        df0 =np.mat([df0['cov'][0],df0['cov'][1],df0['lik']])
        df0=df0.reshape(df0.shape[0]*df0.shape[1],1)#3,1

        sys.stdout.flush()

        fX = f0
        i = i + (length < 0)
        s = np.mat(-1*df0)#3,1

        d0 = -np.dot(s.T,s)#1

        x3 = red / (1 - d0) #1     # initial step is red/(|s|+1)

        while i < abs(length): # while not finished
            i = i + (length > 0) # count iterations?!
            X0 = parm
            F0 = f0
            dF0 = df0 # make a copy of current values
            if length > 0:
                M = MAX
            else:
                M = min(MAX, -length-i)
            while 1 : # keep extrapolating as long as necessary
                x2 = 0
                f2 = f0
                d2 = d0
                f3 = f0
                df3 = df0
                success = 0

                while (success==0 and M>0):
                    M = M - 1
                    i = i + (length < 0)  # count epochs?!
                    print("1s",s)
                    print("1x3",x3)

                    parm_local = hyp.rewrap(parm + s*x3)
                    try:
                        f3, df3 = hyp.gp_my(parm_local, T, N, p, sign, x, y, DX, x0)
                        df3 = [df3["cov"][0], df3["cov"][1], df3["lik"]]
                        # if any([isnan(f3), isinf(f3), any(isnan(df3) + isinf(df3))]):
                        #     print(' ')
                        success = 1

                    except:   # catch any error which occured in f
                        x3 = (x2 + x3) / 2  # bisect and try again
                if f3 < F0:
                    X0 = parm+s*x3
                    F0 = f3
                    dF0 = df3  # keep best values

                d3 = np.dot(df3,s)

                #repair  # if any([d3 > SIG * d0 , f3 > f0 + x3 * RHO * d0 , M == 0]):  # are we done extrapolating?
                #      break
                # print(SIG)
                # print(d0)
                # print(RHO)
                # print(x3)
                # exit()
                d0=d0[0][0]
                x3=x3[0][0]
                myp1=d3 > SIG * d0
                myp2=f3 > f0 + x3 * RHO * d0
                if any([myp1 , myp2 , M == 0]):  # are we done extrapolating?
                     break

                x1 = x2
                f1 = f2
                d1 = d2 # move point 2 to point 1
                x2 = x3
                f2 = f3
                d2 = d3  # move point 3 to point 2
                if np.isnan(f1).any:
                    f1=0
                if np.isnan(f2).any:
                    f2=0
                A = 6 * (f1 - f2) + 3 * (d2 + d1) *(x2 - x1)  # make cubic extrapolation
                B = 3 * (f2 - f1) - (2 * d1 + d2) *(x2 - x1)

                # print("B",B)
                # print("A", np.shape(A))#9,1
                # print(scipy.linalg.sqrtm(np.dot(B.T , B)))
                # print("np.dot(d1 , math.pow((x2 - x1),2))",np.dot(d1 , math.pow((x2 - x1),2)))#9,1
                # print(x1)
                # print("d1",np.shape(d1))#9,1
                # print("x2-1",x2-x1)#1,1
                # prod = [a * b for a,b in zip(A, d1)]
                # prod=sum(prod)
                #
                #
                # print("A * d1  *(x2 - x1)",np.dot(A,d1))
                # print("(x2 - x1)",(x2 - x1))
                x3 = x1 - np.dot(d1 , math.pow((x2 - x1),2))  / (B + scipy.linalg.sqrtm(np.dot(B, B) - np.dot(A,d1) *(x2 - x1))) # num. error possible, ok!
                print("x3",x3)

                if any([x3<0,np.isnan(x3)==True,np.isinf(x3)==True,np.isreal(x3)==True]): #~isreal(x3) |  isnan(x3) |  isinf(x3) |  x3 < 0 :  # num prob | wrong sign?
                    x3 = x2 * EXT  # extrapolate maximum amount
                elif x3 > x2 * EXT :  # new point beyond extrapolation limit?
                    x3 = x2 * EXT  # extrapolate maximum amount
                elif x3 < x2 + INT * (x2 - x1) :  # new point too close to previous point?
                    x3 = x2 + INT * (x2 - x1)

            while (((abs(d3) > -SIG * d0) | (f3 > f0 + x3 * RHO * d0)) &  (M > 0 ))[0,0]:  # keep interpolating
                if ((d3 > 0)  | (f3 > f0 + x3 * RHO * d0))[0,0] :  # choose subinterval

                    x4 = x3
                    f4 = f3
                    d4 = d3 # move point 3 to point 4

                else:

                    x2 = x3
                    f2 = f3
                    d2 = d3  # move point 3 to point 2
                if f4 > f0:
                    x3 = x2 - (0.5 * d2 * math.pow((x4 - x2) , 2)) / (f4 - f2 - d2 * (x4 - x2))  # quadratic interpolation
                else:
                    ##(x4 - x2)为1*1矩阵，变为数值(x4 - x2)[0,0]可解决和其他矩阵计算维度不匹配的情况
                    A = 6 * (f2 - f4) / (x4 - x2) + 3 * (d4 + d2)  # cubic interpolation
                    B = 3 * (f4 - f2) - (2 * d2 + d4) * (x4 - x2)[0,0]

                    #d2为1*1矩阵，变为数值d2[0,0]可解决和其他矩阵计算维度不匹配的情况
                    x3 = x2 + (np.sqrt(np.dot(B.T , B) - A * d2[0,0] *math.pow ((x4 - x2), 2)) - B) / A # num. error possible, ok!

                #用|比OR好，getA1将多维matrix变为一维数组返回，使得可以使用any() 和 all() 函数。
                if any((np.isnan(x3) | np.isinf(x3)).getA1()):
                    x3 = (x2 + x4) / 2  # if we had a numerical problem then bisect

                Ka=min(x3, (x4 - INT * (x4 - x2)))

                #repair #x3 = max(Ka, Pa)  # don't accept too close
                Pa=(x2 + INT * (x4 - x2))
                if (Ka>Pa):
                    x3=Ka
                else:
                    x3=Pa
                f3, df3 = hyp.gp_my( hyp.rewrap(parm + x3 * s.T), T, N, p, sign, x, y, DX, x0)

                df3 = np.mat([df3["cov"][0], df3["cov"][1], df3["lik"]])#1,3原是3，1
                df3=df3.reshape(df3.shape[0]*df3.shape[1],1)#与原相同

                if f3 < F0:
                    X0 = parm+x3 * s.T
                    F0 = f3
                    dF0 = df3  # keep best values
                M = M - 1
                i = i + (length < 0)  # count epochs?!
                d3 = np.dot(df3.T,s)#df3*s.T# new slope#与原相同

            if all(((abs(d3) < -SIG * d0) &  (f3 < f0 + x3 * RHO * d0)).getA1()) :  # if line search succeeded

                parm = parm + x3 * s.T#1，3原是3，1
                f0 = f3
                #
                fX = np.vstack((fX.T,f0))#[fX.T, f0].T  # update variables
                #print('%s %6i;  Value %4.6e\r', S, i, f0)
                #print(S)
                #print(i)
                #print("value",value)
                sys.stdout.flush()
                # print("s",s.shape)
                # print("np.dot(df0.T,df0)",np.dot(df3.T,df3)-np.dot(df0.T , df3) / np.dot(df0.T,df0))
                # exit()

                s = np.dot(s,(np.dot(df3.T,df3)-np.dot(df0.T , df3) / np.dot(df0.T,df0)))- df3 #Polack-Ribiere CG direction

                df0 = df3 # swap derivatives
                d3 = d0
                d0 = df0.T*s
                #add find negative
                r,c=d0.shape
                d0=d0.reshape(r*c,1)
                d0=d0.tolist()

                if all(n[0]> 0 for n in d0):   # new slope must be negative
                    s = -np.mat(df0)
                    d0 = -np.dot(s.T,s ) #otherwise use steepest direction
                    x3 = x3 * np.min(RATIO, d3 / (d0-2.2251e-308))  # slope ratio but max RATIO
                    print("3ifx3",x3)
                    ls_failed = 0  # this line search did not fail
            else:
                parm = X0
                f0 = F0
                df0 = dF0  # restore best point so far
                if ls_failed | i > abs(length) :  # line search failed twice in a row
                    break  # or we ran out of time, so we give up
                s =-np.mat(df0)

                d0 = -np.dot(s.T,s )                  # try steepest

                x3 = 1 / (1 - d0)
                print("3el3x",x3)

                ls_failed = 1  # this line search failed
        print(parm)
        #parm=np.matrix([parm])
        parm=hyp.rewrap(parm)
        sys.stdout.flush()
        return parm,fX

if __name__ == '__main__':
    # #data
    path='./datatest20000_2_5_tri.npz'
    dataset = np.load(path)
    Data= dataset['data'][:,:20]

    p = 1
    time_series = Data.T
    T,N = np.shape(time_series) # number of dimension of the data vector
    train_t = np.array([i for i in range(p, T)]).T
    train_t=train_t.reshape(T-1,1)

    #T_train
    T_train = len(train_t)  #the number of time point for training data

    #train_x(9*3)
    train_x =np.array(time_series[train_t ,:])#
    tmp = np.ones([np.shape(train_x)[0],1])
    train_x = train_x.reshape(-1, 2)
    train_x = np.hstack((train_x, tmp))
    train_x = train_x.reshape(-1, 3)

    #train_yv(18*1)
    train_y = time_series[train_t,:].reshape(-1,2)
    train_yv = train_y.reshape(np.shape(train_y)[0]*np.shape(train_y)[1],1)#reshape it to a column vector

    #DX_train
    DX_train = np.zeros([N * T_train, N * (N * p + 1) * T_train])
    #print(N * T_train)
    for i in range(N * T_train):
        #print(i)
        DX_train[i][i * (N * p + 1):(i+1) * (N * p + 1)]=train_x[math.ceil((i-3) / N)][:]
        # if(i>72):
        #     DT=DX_train
        #     print(DX_train)

    obj = GP(0.1,1.1,1.1)

    parm = {"mean": obj.mean, "lik": obj.lik, "cov": obj.cov}

    parm2, fhyp2 = obj.minimize(parm, 100, T, N, p, 0, train_t, train_yv, DX_train, train_x)
    print("parm2, fhyp2",parm2, fhyp2)
    nlZ, dnlZ, nlhood, posterior_mean, posterior_covariance = obj.infExact_delayed(parm2,T, N, p, 1, train_t,
                                                                                   train_yv, DX_train, train_x)
    print("posterior_mean, posterior_covariance",posterior_mean.shape, posterior_covariance.shape)
    p_mean = posterior_mean.reshape( N * (N * p + 1), T-1)
    posterior_variance = np.diag(posterior_covariance)
    p_variance = posterior_variance.reshape( N * (N * p + 1), int(len(posterior_variance) / (N * (N * p + 1))))
    number_of_func = N * (N * p + 1)#6

    z = train_t.T

    plt.figure("line")
    for i in range(number_of_func):
        plt.subplot(N, N * p + 1, i+1)
        if i<N:
            print("p_meani",p_mean[i,:].shape,p_mean[i,:])
            plt.plot(z[0], p_mean[i, :], '-')
            x_major_locator = MultipleLocator(1)
            plt.xlim([1, T-1])
            plt.xlabel("time")
            plt.title("a1%d" % (i+1))
        elif i==N:
            plt.plot(z[0], p_mean[i, :], '-')
            x_major_locator = MultipleLocator(1)
            plt.xlim([1, T-1])
            plt.xlabel("time")
            plt.title('g1')
        elif i<2*N+1:
            plt.plot(z[0], p_mean[i, :], '-')
            plt.xlim([1, T-1])
            x_major_locator = MultipleLocator(1)
            plt.xlabel("time")
            plt.title("a2%d" % (i-2))
        else :
            plt.plot(z[0], p_mean[i, :], '-')
            plt.xlim([1, T-1])
            plt.xlabel("time")
            x_major_locator = MultipleLocator(1)
            plt.title('g2')

    plt.savefig("time_varying_coefficients")
    #plt.show()
    plt.figure("heatmap")
    sns.heatmap(p_mean, annot=True)
    plt.savefig("time_varying_coefficients-heatmap")




